{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Regular lab Question – 7"
      ],
      "metadata": {
        "id": "mmHcBShP_Uk5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lab Assignment: LSTM Lab Exercise: Poem Generation"
      ],
      "metadata": {
        "id": "FJ9Y1LL1_YOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Dataset Preparation:\n",
        "- Download the dataset from Kaggle.\n",
        "- Load the dataset and explore the columns to understand the structure.\n",
        "- Concatenate multiple poems into a single text corpus, separating them by newline characters for clarity."
      ],
      "metadata": {
        "id": "0Wh0EmbX_hzR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2XUxRU__PnN",
        "outputId": "69e4c360-073d-4717-df13-c00800516ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/tgdivy/poetry-foundation-poems?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8.88M/8.88M [00:00<00:00, 50.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/tgdivy/poetry-foundation-poems/versions/1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import kagglehub\n",
        "\n",
        "path = kagglehub.dataset_download(\"tgdivy/poetry-foundation-poems\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(os.path.join(path, \"PoetryFoundationData.csv\"), nrows=1000)"
      ],
      "metadata": {
        "id": "nJ2tYgW_C9SO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean data\n",
        "df['Poem'] = df['Poem'].str.replace(r'\\s+', ' ', regex=True)  # Replace multiple spaces/newlines with a single space\n",
        "df['Title'] = df['Title'].str.replace(r'\\s+', ' ', regex=True)\n",
        "df['input'] = df['Title'] + ' *** ' + df['Poem']\n",
        "\n",
        "\n",
        "# Explore the columns\n",
        "print(df.columns)\n",
        "\n",
        "input_data = df['input'].values.tolist()\n",
        "\n",
        "# Print a portion of the corpus to verify\n",
        "print(input_data[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92z-tuL-Do__",
        "outputId": "aeabbffe-d0b9-4d21-e2c1-3baf7a31d73e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Unnamed: 0', 'Title', 'Poem', 'Poet', 'Tags', 'input'], dtype='object')\n",
            "[\" Objects Used to Prop Open a Window  ***  Dog bone, stapler, cribbage board, garlic press because this window is loose—lacks suction, lacks grip. Bungee cord, bootstrap, dog leash, leather belt because this window had sash cords. They frayed. They broke. Feather duster, thatch of straw, empty bottle of Elmer's glue because this window is loud—its hinges clack open, clack shut. Stuffed bear, baby blanket, single crib newel because this window is split. It's dividing in two. Velvet moss, sagebrush, willow branch, robin's wing because this window, it's pane-less. It's only a frame of air. \", ' The New Church  ***  The old cupola glinted above the clouds, shone among fir trees, but it took him an hour for the half mile all the way up the hill. As he trailed, the village passed him by, greeted him, asked about his health, but everybody hurried to catch the mass, left him leaning against fences, measuring the road with the walking stick he sculpted. He yearned for the day when the new church would be built—right across the road. Now it rises above the moon: saints in frescoes meet the eye, and only the rain has started to cut through the shingles on the roof of his empty house. The apple trees have taken over the sky, sequestered the gate, sidled over the porch. ', \" Look for Me  ***  Look for me under the hood of that old Chevrolet settled in weeds at the end of the pasture. I'm the radiator that spent its years bolted in front of an engine shoving me forward into the wind. Whatever was in me in those days has mostly leaked away, but my cap's still screwed on tight and I know the names of all these tattered moths and broken grasshoppers the rest of you've forgotten. \"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Data Preprocessing:\n",
        "- Convert the text to lowercase and remove special characters or\n",
        "punctuation if necessary.\n",
        "- Tokenize the text (e.g., convert each word to a unique integer).\n",
        "- Use a sliding window to create sequences of words for the LSTM model.\n",
        " - For example, if n=5, create sequences of 5 words with the 6th word as the target.\n",
        "- Pad the sequences so that they all have the same length."
      ],
      "metadata": {
        "id": "povJzP2t_kLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "# Tokenize the text (convert each word to a unique integer)\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(input_data)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(total_words)"
      ],
      "metadata": {
        "id": "OOv4nv-b_uJ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf59e13-85bc-4b5c-b3cf-4b6b0d1f2fb7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create input sequences using sequences of words\n",
        "input_sequences = []\n",
        "for line in input_data:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, min(len(token_list), 50)):  # Cap sequence length to 50\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Calculate max_sequence_len\n",
        "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
        "\n",
        "# Pad sequences and create predictors and labels\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "predictors, label = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "label = to_categorical(label, num_classes=total_words)"
      ],
      "metadata": {
        "id": "5MgO7503SGLg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Generator function to yield batches of data\n",
        "def data_generator(predictors, labels):\n",
        "    dataset_size = len(predictors)\n",
        "    indices = np.arange(dataset_size)\n",
        "    np.random.shuffle(indices)\n",
        "    for idx in indices:\n",
        "        yield predictors[idx], labels[idx]\n",
        "\n",
        "# Create a TensorFlow Dataset from the generator function\n",
        "dataset = tf.data.Dataset.from_generator(\n",
        "    lambda: data_generator(predictors, label),\n",
        "    output_signature=(\n",
        "        tf.TensorSpec(shape=(predictors.shape[1],), dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=(label.shape[1],), dtype=tf.float32)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Shuffle and batch the dataset\n",
        "dataset = dataset.shuffle(buffer_size=10000).batch(batch_size).repeat()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_size = 100000\n",
        "val_size = 20000\n",
        "\n",
        "train_dataset = dataset.take(train_size // batch_size)\n",
        "val_dataset = dataset.skip(train_size // batch_size).take(val_size // batch_size)"
      ],
      "metadata": {
        "id": "bOLeB2lFSmn2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
        "import pickle\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "checkpoint_path = \"model_checkpoint.keras\"\n",
        "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                      monitor='val_loss',\n",
        "                                      save_best_only=True,\n",
        "                                      mode='min',\n",
        "                                      verbose=1)\n",
        "\n",
        "# Define EarlyStopping callback\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
      ],
      "metadata": {
        "id": "Sfki2a3CQCPV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. LSTM Model Development:\n",
        "- Define an LSTM model with the following structure:\n",
        " - An embedding layer with an appropriate input dimension (based\n",
        "on vocabulary size) and output dimension (e.g., 100).\n",
        " - One or two LSTM layers with 100 units each.\n",
        "\n",
        " - A dropout layer with a rate of 0.2 to prevent overfitting.\n",
        " - A dense output layer with softmax activation for word prediction."
      ],
      "metadata": {
        "id": "EnXA13rn_w3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(total_words, 50))\n",
        "    model.add(LSTM(100))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "    return model\n",
        "\n",
        "model = create_model()\n",
        "model.build(input_shape=(None, max_sequence_len))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "Y3mvcJbw_3G8",
        "outputId": "2bac4510-ab35-4ad9-90c3-de1dbafebb89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │       \u001b[38;5;34m1,510,800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │          \u001b[38;5;34m60,400\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30216\u001b[0m)               │       \u001b[38;5;34m3,051,816\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,510,800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">60,400</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30216</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,051,816</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,623,016\u001b[0m (17.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,623,016</span> (17.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,623,016\u001b[0m (17.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,623,016</span> (17.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Training:\n",
        "- Compile the model with categorical cross-entropy as the loss function\n",
        "and accuracy as the metric.\n",
        "- Train the model on the sequences for 10-20 epochs (or until it achieves\n",
        "satisfactory performance)."
      ],
      "metadata": {
        "id": "KDyKw7di_3t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with batching\n",
        "history = model.fit(train_dataset,\n",
        "                    epochs=30,\n",
        "                    verbose=1,\n",
        "                    validation_data=val_dataset,\n",
        "                    callbacks=[early_stopping_callback, checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgaGoPnKF4C7",
        "outputId": "cc086547-3f9f-4c34-bb50-32e0dcecd7e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0627 - loss: 7.7042\n",
            "Epoch 1: val_loss improved from inf to 6.76196, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 32ms/step - accuracy: 0.0627 - loss: 7.7041 - val_accuracy: 0.0747 - val_loss: 6.7620\n",
            "Epoch 2/30\n",
            "\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0764 - loss: 6.7641\n",
            "Epoch 2: val_loss improved from 6.76196 to 6.15718, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 29ms/step - accuracy: 0.0764 - loss: 6.7640 - val_accuracy: 0.0966 - val_loss: 6.1572\n",
            "Epoch 3/30\n",
            "\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0949 - loss: 6.2290\n",
            "Epoch 3: val_loss improved from 6.15718 to 5.55426, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 31ms/step - accuracy: 0.0949 - loss: 6.2290 - val_accuracy: 0.1230 - val_loss: 5.5543\n",
            "Epoch 4/30\n",
            "\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1166 - loss: 5.6786\n",
            "Epoch 4: val_loss improved from 5.55426 to 4.90411, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 30ms/step - accuracy: 0.1166 - loss: 5.6785 - val_accuracy: 0.1698 - val_loss: 4.9041\n",
            "Epoch 5/30\n",
            "\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1457 - loss: 5.1191\n",
            "Epoch 5: val_loss improved from 4.90411 to 4.31545, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 32ms/step - accuracy: 0.1457 - loss: 5.1191 - val_accuracy: 0.2360 - val_loss: 4.3154\n",
            "Epoch 6/30\n",
            "\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1939 - loss: 4.5676\n",
            "Epoch 6: val_loss improved from 4.31545 to 3.71059, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 29ms/step - accuracy: 0.1939 - loss: 4.5676 - val_accuracy: 0.3271 - val_loss: 3.7106\n",
            "Epoch 7/30\n",
            "\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2574 - loss: 4.0524\n",
            "Epoch 7: val_loss improved from 3.71059 to 3.20731, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 29ms/step - accuracy: 0.2574 - loss: 4.0524 - val_accuracy: 0.4069 - val_loss: 3.2073\n",
            "Epoch 8/30\n",
            "\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3251 - loss: 3.5880\n",
            "Epoch 8: val_loss improved from 3.20731 to 2.79684, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 29ms/step - accuracy: 0.3251 - loss: 3.5880 - val_accuracy: 0.4752 - val_loss: 2.7968\n",
            "Epoch 9/30\n",
            "\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3890 - loss: 3.1844\n",
            "Epoch 9: val_loss improved from 2.79684 to 2.41513, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 29ms/step - accuracy: 0.3890 - loss: 3.1844 - val_accuracy: 0.5401 - val_loss: 2.4151\n",
            "Epoch 10/30\n",
            "\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4440 - loss: 2.8464\n",
            "Epoch 10: val_loss improved from 2.41513 to 2.10240, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 31ms/step - accuracy: 0.4440 - loss: 2.8464 - val_accuracy: 0.6010 - val_loss: 2.1024\n",
            "Epoch 11/30\n",
            "\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4921 - loss: 2.5530\n",
            "Epoch 11: val_loss improved from 2.10240 to 1.81725, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 31ms/step - accuracy: 0.4921 - loss: 2.5530 - val_accuracy: 0.6496 - val_loss: 1.8172\n",
            "Epoch 12/30\n",
            "\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5342 - loss: 2.3065\n",
            "Epoch 12: val_loss improved from 1.81725 to 1.60923, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 31ms/step - accuracy: 0.5342 - loss: 2.3065 - val_accuracy: 0.6882 - val_loss: 1.6092\n",
            "Epoch 13/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5699 - loss: 2.0842\n",
            "Epoch 13: val_loss improved from 1.60923 to 1.43100, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 31ms/step - accuracy: 0.5699 - loss: 2.0842 - val_accuracy: 0.7240 - val_loss: 1.4310\n",
            "Epoch 14/30\n",
            "\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6013 - loss: 1.9065\n",
            "Epoch 14: val_loss improved from 1.43100 to 1.30173, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 29ms/step - accuracy: 0.6013 - loss: 1.9065 - val_accuracy: 0.7471 - val_loss: 1.3017\n",
            "Epoch 15/30\n",
            "\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6280 - loss: 1.7508\n",
            "Epoch 15: val_loss improved from 1.30173 to 1.14085, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 31ms/step - accuracy: 0.6280 - loss: 1.7509 - val_accuracy: 0.7747 - val_loss: 1.1409\n",
            "Epoch 16/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6506 - loss: 1.6231\n",
            "Epoch 16: val_loss improved from 1.14085 to 1.02887, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 31ms/step - accuracy: 0.6506 - loss: 1.6231 - val_accuracy: 0.8037 - val_loss: 1.0289\n",
            "Epoch 17/30\n",
            "\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6768 - loss: 1.4925\n",
            "Epoch 17: val_loss improved from 1.02887 to 0.91730, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 31ms/step - accuracy: 0.6768 - loss: 1.4926 - val_accuracy: 0.8238 - val_loss: 0.9173\n",
            "Epoch 18/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6861 - loss: 1.4052\n",
            "Epoch 18: val_loss improved from 0.91730 to 0.83131, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 29ms/step - accuracy: 0.6861 - loss: 1.4052 - val_accuracy: 0.8391 - val_loss: 0.8313\n",
            "Epoch 19/30\n",
            "\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7063 - loss: 1.3121\n",
            "Epoch 19: val_loss improved from 0.83131 to 0.76840, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 31ms/step - accuracy: 0.7063 - loss: 1.3121 - val_accuracy: 0.8520 - val_loss: 0.7684\n",
            "Epoch 20/30\n",
            "\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7237 - loss: 1.2280\n",
            "Epoch 20: val_loss improved from 0.76840 to 0.68099, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 30ms/step - accuracy: 0.7237 - loss: 1.2281 - val_accuracy: 0.8740 - val_loss: 0.6810\n",
            "Epoch 21/30\n",
            "\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7386 - loss: 1.1487\n",
            "Epoch 21: val_loss improved from 0.68099 to 0.63630, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 31ms/step - accuracy: 0.7386 - loss: 1.1488 - val_accuracy: 0.8801 - val_loss: 0.6363\n",
            "Epoch 22/30\n",
            "\u001b[1m3124/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7509 - loss: 1.0890\n",
            "Epoch 22: val_loss improved from 0.63630 to 0.58448, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 30ms/step - accuracy: 0.7509 - loss: 1.0890 - val_accuracy: 0.8891 - val_loss: 0.5845\n",
            "Epoch 23/30\n",
            "\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7584 - loss: 1.0390\n",
            "Epoch 23: val_loss improved from 0.58448 to 0.54275, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 31ms/step - accuracy: 0.7584 - loss: 1.0390 - val_accuracy: 0.8982 - val_loss: 0.5427\n",
            "Epoch 24/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7683 - loss: 0.9906\n",
            "Epoch 24: val_loss improved from 0.54275 to 0.49135, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 31ms/step - accuracy: 0.7683 - loss: 0.9906 - val_accuracy: 0.9076 - val_loss: 0.4913\n",
            "Epoch 25/30\n",
            "\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7733 - loss: 0.9539\n",
            "Epoch 25: val_loss improved from 0.49135 to 0.47515, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 31ms/step - accuracy: 0.7733 - loss: 0.9539 - val_accuracy: 0.9113 - val_loss: 0.4751\n",
            "Epoch 26/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7840 - loss: 0.9033\n",
            "Epoch 26: val_loss improved from 0.47515 to 0.43944, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 30ms/step - accuracy: 0.7840 - loss: 0.9033 - val_accuracy: 0.9169 - val_loss: 0.4394\n",
            "Epoch 27/30\n",
            "\u001b[1m3122/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7912 - loss: 0.8696\n",
            "Epoch 27: val_loss improved from 0.43944 to 0.41287, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 29ms/step - accuracy: 0.7912 - loss: 0.8697 - val_accuracy: 0.9237 - val_loss: 0.4129\n",
            "Epoch 28/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7932 - loss: 0.8447\n",
            "Epoch 28: val_loss improved from 0.41287 to 0.38352, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 30ms/step - accuracy: 0.7932 - loss: 0.8447 - val_accuracy: 0.9274 - val_loss: 0.3835\n",
            "Epoch 29/30\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8043 - loss: 0.8020\n",
            "Epoch 29: val_loss improved from 0.38352 to 0.36753, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 31ms/step - accuracy: 0.8043 - loss: 0.8020 - val_accuracy: 0.9319 - val_loss: 0.3675\n",
            "Epoch 30/30\n",
            "\u001b[1m3123/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8127 - loss: 0.7670\n",
            "Epoch 30: val_loss improved from 0.36753 to 0.34201, saving model to model_checkpoint.keras\n",
            "\u001b[1m3125/3125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 29ms/step - accuracy: 0.8127 - loss: 0.7670 - val_accuracy: 0.9370 - val_loss: 0.3420\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"trained_model.h5\")\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('trained_model.h5')"
      ],
      "metadata": {
        "id": "z7avOG3dG20K",
        "outputId": "8f576978-56cc-470e-9fae-7d59837357ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Text Generation:\n",
        "- After training, write a function to generate new poetry lines:\n",
        " - Start with a seed text (e.g., a short phrase).\n",
        " - Predict the next word, append it to the seed text, and use this\n",
        "updated text to predict the following word.\n",
        " - Repeat this process for a specified number of words or lines.\n",
        "- Generate multiple lines of poetry using different starting phrases."
      ],
      "metadata": {
        "id": "Bv-xVLg0_7J1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poetry(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "seed_texts = [\"The sun\", \"Love's embrace\", \"Autumn leaves\"]\n",
        "for seed_text in seed_texts:\n",
        "    generated_poetry = generate_poetry(seed_text, 20, model, max_sequence_len, tokenizer)\n",
        "    print(f\"Generated poetry with seed '{seed_text}':\\n{generated_poetry}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmYJzUskLu8r",
        "outputId": "1354a1b1-e1ef-4148-c509-fec60b684419"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated poetry with seed 'The sun':\n",
            "The sun near the camp was a river and the poem is death of the house it takes on a world and\n",
            "\n",
            "Generated poetry with seed 'Love's embrace':\n",
            "Love's embrace angelo when i was born a single donkey i work i was at a hurry and do is you shall\n",
            "\n",
            "Generated poetry with seed 'Autumn leaves':\n",
            "Autumn leaves when i stood under a days at the office i know that i find my mother what is not so\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Evaluation and Experimentation:\n",
        "- Experiment with different LSTM layer sizes, dropout rates, and sequence\n",
        "lengths to observe their effects on generated text quality.\n",
        "- Try adding additional LSTM layers and tuning hyperparameters to improve\n",
        "the creativity or fluency of generated poetry."
      ],
      "metadata": {
        "id": "3F-uNoTyAARr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "model2 = Sequential()\n",
        "model2.add(Embedding(input_dim=vocab_size, output_dim=100))\n",
        "model2.add(LSTM(50, return_sequences=True))\n",
        "model2.add(LSTM(50))\n",
        "model2.add(Dropout(0.4))  # Dropout layer to prevent overfitting\n",
        "model2.add(Dense(vocab_size, activation='softmax'))  # Output layer for word prediction\n",
        "\n",
        "# Compile the model\n",
        "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model2.build(input_shape=(None, max_sequence_len))\n",
        "model2.summary()"
      ],
      "metadata": {
        "id": "SIfyv9VCADNI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "82ece7bd-ebb7-4acf-ba62-852ddfbdb97c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │       \u001b[38;5;34m3,021,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m)              │          \u001b[38;5;34m30,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │          \u001b[38;5;34m20,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30216\u001b[0m)               │       \u001b[38;5;34m1,541,016\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,021,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">30,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">20,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30216</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,541,016</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,613,016\u001b[0m (17.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,613,016</span> (17.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,613,016\u001b[0m (17.60 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,613,016</span> (17.60 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_poetry(seed_text, next_words, model, max_sequence_len, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len - 1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "seed_texts = [\"Whispers of night\", \"A lone star\", \"In dreams we wander\"]\n",
        "for seed_text in seed_texts:\n",
        "    generated_poetry = generate_poetry(seed_text, 20, model, max_sequence_len, tokenizer)\n",
        "    print(f\"Generated poetry with seed '{seed_text}':\\n{generated_poetry}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1wfYutW9ERJ",
        "outputId": "4f95f405-cbe8-4011-92c5-c75c6ad9695a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated poetry with seed 'Whispers of night':\n",
            "Whispers of night over us in all at night my father is even a young house gone gone just this own dark soft\n",
            "\n",
            "Generated poetry with seed 'A lone star':\n",
            "A lone star three and ” if we woke past among his years of each water is my body is law with a\n",
            "\n",
            "Generated poetry with seed 'In dreams we wander':\n",
            "In dreams we wander a little patch of night is an house in lie having a maze in shadow but a little body has\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpretation\n",
        "The code utilizes an LSTM model to generate new poetry lines by learning patterns and dependencies in a dataset of poems. It involves preparing the dataset, creating sequences, training an LSTM, and iteratively predicting the next word based on a seed text to generate new text. The goal is to produce text that has similar characteristics to the training data, like style and structure.\n",
        "\n",
        "By adjusting the model's parameters and experimenting with different seed texts, users can influence the creativity and fluency of the generated poetry.\n"
      ],
      "metadata": {
        "id": "BnvMTJOs90kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated poetry lines resemble the style and structure of the original dataset because the LSTM model has learned syntactic and thematic patterns from it. When each seed text is provided, the model uses it as a starting point and builds upon it, generating coherent lines that match the tone, rhythm, and sometimes even the sentiment of the original poems."
      ],
      "metadata": {
        "id": "J11UODvP-aSV"
      }
    }
  ]
}